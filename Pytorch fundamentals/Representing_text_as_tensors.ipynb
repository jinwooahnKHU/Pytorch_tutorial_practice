{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Representing text as tensors.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPzx2E6H7rDzHrkHeVe3T5h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinwooahnKHU/Pytorch_tutorial_practice/blob/main/Representing_text_as_tensors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Representing text"
      ],
      "metadata": {
        "id": "zyr6NfIENpdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# token : atomic piece of text. Could be letters, words or parts of words\n",
        "# tokenization : converting text into a sequence of tokens\n",
        "# vectorization : assign each token to a number \n",
        "\n",
        "#huggingface, gensim, nltk, opencv, torch 관련 패키지들 다운로드\n",
        "\n",
        "!pip install -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GmDHXeYNrn4",
        "outputId": "a5041089-1e7b-452d-cea2-9f5f4f8441ac"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim==3.8.3 in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 1)) (3.8.3)\n",
            "Requirement already satisfied: huggingface==0.0.1 in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 2)) (0.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 3)) (3.2.2)\n",
            "Requirement already satisfied: nltk==3.5 in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 4)) (3.5)\n",
            "Requirement already satisfied: numpy==1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 5)) (1.18.5)\n",
            "Requirement already satisfied: opencv-python==4.5.1.48 in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 6)) (4.5.1.48)\n",
            "Requirement already satisfied: Pillow==7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 8)) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 9)) (1.4.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 10)) (1.8.1)\n",
            "Requirement already satisfied: torchaudio==0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 11)) (0.8.1)\n",
            "Requirement already satisfied: torchinfo==0.0.8 in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 12)) (0.0.8)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 13)) (0.9.1)\n",
            "Requirement already satisfied: torchvision==0.9.1 in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 14)) (0.9.1)\n",
            "Requirement already satisfied: transformers==4.3.3 in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 15)) (4.3.3)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.3->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.3->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 1)) (6.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 4)) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 4)) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 4)) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 10)) (4.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 15)) (21.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 15)) (0.0.53)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 15)) (3.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 15)) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 15)) (4.11.4)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 15)) (0.10.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 3)) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 3)) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 3)) (0.11.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 8)) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.3.3->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 15)) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 15)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 15)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 15)) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 15)) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text classification Task"
      ],
      "metadata": {
        "id": "2SinJafAVO5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# text classification task based on AG_NEWS dataset\n",
        "# classify news headlines into 4 categories(world, sports, business, sci/tech)\n",
        "# dataset is built from torchtext module\n",
        "\n",
        "import torch\n",
        "import torchtext\n",
        "import os\n",
        "import collections\n",
        "\n",
        "os.makedirs('./data', exist_ok=True)\n",
        "#train_dataset, test_dataset contain iterators that return pairs of label(num of classes) and text\n",
        "train_dataset, test_dataset = torchtext.datasets.AG_NEWS(\n",
        "    root='./data'\n",
        ")\n",
        "classes = ['World','Sports','Business','Sci/Tech']\n"
      ],
      "metadata": {
        "id": "Oc6MJi40VQSA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(train_dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TL1jGBCVutP",
        "outputId": "1c7a7fc5-74b1-40a2-fed1-96f92a3ef5af"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3,\n",
              " \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, x in zip(range(5), train_dataset): # iterator 이므로 zip으로 호출\n",
        "  print(f\"**{classes[x[0]]}** -> {x[1]}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGMjhaETWHQx",
        "outputId": "b177a07d-a47e-4298-86a5-3b4f46cbccfc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Sci/Tech** -> Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private investment firm Carlyle Group,\\which has a reputation for making well-timed and occasionally\\controversial plays in the defense industry, has quietly placed\\its bets on another part of the market.\n",
            "\n",
            "**Sci/Tech** -> Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\about the economy and the outlook for earnings are expected to\\hang over the stock market next week during the depth of the\\summer doldrums.\n",
            "\n",
            "**Sci/Tech** -> Iraq Halts Oil Exports from Main Southern Pipeline (Reuters) Reuters - Authorities have halted oil export\\flows from the main pipeline in southern Iraq after\\intelligence showed a rebel militia could strike\\infrastructure, an oil official said on Saturday.\n",
            "\n",
            "**Sci/Tech** -> Oil prices soar to all-time record, posing new menace to US economy (AFP) AFP - Tearaway world oil prices, toppling records and straining wallets, present a new economic menace barely three months before the US presidential elections.\n",
            "\n",
            "**Sci/Tech** -> Stocks End Up, But Near Year Lows (Reuters) Reuters - Stocks ended slightly higher on Friday\\but stayed near lows for the year as oil prices surged past  #36;46\\a barrel, offsetting a positive outlook from computer maker\\Dell Inc. (DELL.O)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, test_dataset = torchtext.datasets.AG_NEWS(root='./data')\n",
        "train_dataset = list(train_dataset)\n",
        "test_dataset = list(test_dataset)"
      ],
      "metadata": {
        "id": "WY00CY9OWQyb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenization and Vectorization"
      ],
      "metadata": {
        "id": "G5VM-h-eWtV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#convert text into numbers\n",
        "tokenizer = torchtext.data.utils.get_tokenizer('basic_english')"
      ],
      "metadata": {
        "id": "y6j9yeZCWvdf"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_sentence = train_dataset[0][1]\n",
        "second_sentence = train_dataset[1][1]\n",
        "\n",
        "f_tokens = tokenizer(first_sentence)\n",
        "s_tokens = tokenizer(second_sentence)\n",
        "\n",
        "print(f'\\nfirst token list:\\n{f_tokens}')\n",
        "print(f'\\nsecond token list:\\n{s_tokens}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6PWQ14BW44X",
        "outputId": "fff7802a-c81f-4a82-d179-55a37a5d6745"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "first token list:\n",
            "['wall', 'st', '.', 'bears', 'claw', 'back', 'into', 'the', 'black', '(', 'reuters', ')', 'reuters', '-', 'short-sellers', ',', 'wall', 'street', \"'\", 's', 'dwindling\\\\band', 'of', 'ultra-cynics', ',', 'are', 'seeing', 'green', 'again', '.']\n",
            "\n",
            "second token list:\n",
            "['carlyle', 'looks', 'toward', 'commercial', 'aerospace', '(', 'reuters', ')', 'reuters', '-', 'private', 'investment', 'firm', 'carlyle', 'group', ',', '\\\\which', 'has', 'a', 'reputation', 'for', 'making', 'well-timed', 'and', 'occasionally\\\\controversial', 'plays', 'in', 'the', 'defense', 'industry', ',', 'has', 'quietly', 'placed\\\\its', 'bets', 'on', 'another', 'part', 'of', 'the', 'market', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#build a vocabulary of tokens with \"Counter\" object, then create a \"Vocab\" object \n",
        "# counter은 빈도수세주는 클래스(사전 사용)\n",
        "counter = collections.Counter()\n",
        "for (label, line) in train_dataset:\n",
        "  counter.update(tokenizer(line))\n",
        "\n",
        "#dictionary counter 을 torchtext.vocab사용하면 사전을 build할수있다\n",
        "vocab = torchtext.vocab.Vocab(counter, min_freq=1)"
      ],
      "metadata": {
        "id": "2nCTRc9xXO9B"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwYm5uvwjMUF",
        "outputId": "5199edfb-284d-4c4a-ce07-df3a3dbb7cc2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torchtext.vocab.Vocab at 0x7f3894b1e490>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_lookup = [list((vocab[w], w)) for w in f_tokens]\n",
        "print(f'\\nIndex lockup in 1st sentence:\\n{word_lookup}')\n",
        "\n",
        "word_lookup = [list((vocab[w], w)) for w in s_tokens]\n",
        "print(f'\\nIndex lockup in 2nd sentence:\\n{word_lookup}')"
      ],
      "metadata": {
        "id": "_PISGRmcXj6E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfefdb5f-210f-47d2-da31-2c08c40aab35"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Index lockup in 1st sentence:\n",
            "[[432, 'wall'], [426, 'st'], [2, '.'], [1606, 'bears'], [14839, 'claw'], [114, 'back'], [67, 'into'], [3, 'the'], [849, 'black'], [14, '('], [28, 'reuters'], [15, ')'], [28, 'reuters'], [16, '-'], [50726, 'short-sellers'], [4, ','], [432, 'wall'], [375, 'street'], [17, \"'\"], [10, 's'], [67508, 'dwindling\\\\band'], [7, 'of'], [52259, 'ultra-cynics'], [4, ','], [43, 'are'], [4010, 'seeing'], [784, 'green'], [326, 'again'], [2, '.']]\n",
            "\n",
            "Index lockup in 2nd sentence:\n",
            "[[15875, 'carlyle'], [1073, 'looks'], [855, 'toward'], [1311, 'commercial'], [4251, 'aerospace'], [14, '('], [28, 'reuters'], [15, ')'], [28, 'reuters'], [16, '-'], [930, 'private'], [798, 'investment'], [321, 'firm'], [15875, 'carlyle'], [99, 'group'], [4, ','], [27658, '\\\\which'], [29, 'has'], [6, 'a'], [4460, 'reputation'], [12, 'for'], [565, 'making'], [52791, 'well-timed'], [9, 'and'], [80618, 'occasionally\\\\controversial'], [2126, 'plays'], [8, 'in'], [3, 'the'], [526, 'defense'], [242, 'industry'], [4, ','], [29, 'has'], [3891, 'quietly'], [82815, 'placed\\\\its'], [6575, 'bets'], [11, 'on'], [207, 'another'], [360, 'part'], [7, 'of'], [3, 'the'], [127, 'market'], [2, '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#encode tokenized string into a set of a numbers\n",
        "vocab_size = len(vocab)\n",
        "print(f\"vocab size of {vocab_size}\")\n",
        "\n",
        "#torch.vocab.vocab 으로 만들어진 자료구조에서 .stoi 를 사용하면 string 을 integer로 바꿔줌\n",
        "def encode(x):\n",
        "  return [vocab.stoi[s] for s in tokenizer(x)]\n",
        "\n",
        "vec = encode(first_sentence)\n",
        "print(vec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAq0q_xTjWm3",
        "outputId": "7cc0c345-c068-4fa2-a861-1845469d37cf"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab size of 95812\n",
            "[432, 426, 2, 1606, 14839, 114, 67, 3, 849, 14, 28, 15, 28, 16, 50726, 4, 432, 375, 17, 10, 67508, 7, 52259, 4, 43, 4010, 784, 326, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# decode\n",
        "def decode(x):\n",
        "  return [vocab.itos[i] for i in x]\n",
        "\n",
        "#위에서 encode한 것을 다시 decode\n",
        "decode(vec)"
      ],
      "metadata": {
        "id": "YLeLgALlksmw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "232ed616-828f-4ec7-e242-a3591f37a4f1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['wall',\n",
              " 'st',\n",
              " '.',\n",
              " 'bears',\n",
              " 'claw',\n",
              " 'back',\n",
              " 'into',\n",
              " 'the',\n",
              " 'black',\n",
              " '(',\n",
              " 'reuters',\n",
              " ')',\n",
              " 'reuters',\n",
              " '-',\n",
              " 'short-sellers',\n",
              " ',',\n",
              " 'wall',\n",
              " 'street',\n",
              " \"'\",\n",
              " 's',\n",
              " 'dwindling\\\\band',\n",
              " 'of',\n",
              " 'ultra-cynics',\n",
              " ',',\n",
              " 'are',\n",
              " 'seeing',\n",
              " 'green',\n",
              " 'again',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bigrams, Trigrams, and N-Grams"
      ],
      "metadata": {
        "id": "kSNo2qNGmlFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# some words are part of multi word expressions (ex. \"Hot dog\" is different with hot and dog, so have to make independent vector)\n",
        "# therefore when bi-word, tri-word is useful feature for training classifier, \"N-gram representaions\" are used in document classification\n",
        "\n",
        "# in \"bi-gram representation\", will add all \"word pairs\" to the vocabulary, in addition to original words (기존의 단어장에 2개씩 묶어서 더 넣는다)\n",
        "# to get n-gram representation, we can use ngrams_iterator function\n",
        "\n",
        "from torchtext.data.utils import ngrams_iterator\n",
        "\n",
        "# 마찬가지로 횟수를 세기에 counter 클래스를 사용해준다\n",
        "bi_counter = collections.Counter()\n",
        "for (label, line) in train_dataset:\n",
        "  bi_counter.update(ngrams_iterator(tokenizer(line), ngrams=2))\n",
        "bi_vocab = torchtext.vocab.Vocab(bi_counter, min_freq=2)\n",
        "\n",
        "print(f\"Bigram vocab size = {len(bi_vocab)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCuWcMoImbA6",
        "outputId": "dab4eab1-0907-42c2-e412-442070c489c6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigram vocab size = 481971\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(x):\n",
        "  return [bi_vocab.stoi[s] for s in tokenizer(x)]\n",
        "\n",
        "vec = encode(first_sentence)\n",
        "\n",
        "print(vec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFELakjPr59Y",
        "outputId": "21dbe56c-465b-4527-a16a-ba3e9eaf38f8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[572, 564, 2, 2326, 49106, 150, 88, 3, 1143, 14, 32, 15, 32, 16, 443749, 4, 572, 499, 17, 10, 0, 7, 468770, 4, 52, 7019, 1050, 442, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(x):\n",
        "  return [bi_vocab.itos[s] for s in x]\n",
        "\n",
        "decode(vec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CedJhhZasBza",
        "outputId": "bcb310fd-7ffe-4f80-80be-bfa95a57a7d1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['wall',\n",
              " 'st',\n",
              " '.',\n",
              " 'bears',\n",
              " 'claw',\n",
              " 'back',\n",
              " 'into',\n",
              " 'the',\n",
              " 'black',\n",
              " '(',\n",
              " 'reuters',\n",
              " ')',\n",
              " 'reuters',\n",
              " '-',\n",
              " 'short-sellers',\n",
              " ',',\n",
              " 'wall',\n",
              " 'street',\n",
              " \"'\",\n",
              " 's',\n",
              " '<unk>',\n",
              " 'of',\n",
              " 'ultra-cynics',\n",
              " ',',\n",
              " 'are',\n",
              " 'seeing',\n",
              " 'green',\n",
              " 'again',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ]
}
